{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2befa222-e153-40d4-b3fe-b3f3459d0278",
   "metadata": {},
   "source": [
    "# MNIST Train Implements\n",
    "\n",
    "- 1. Load Data Component\n",
    "- 2. Proc Data Component\n",
    "- 3. Train CNN Component\n",
    "- 4. Train Linear Component\n",
    "- 5. Evaluate Component\n",
    "\n",
    "<br/>\n",
    "\n",
    "- without Metrics\n",
    "- without Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fda2f-6903-4e13-a199-d1293fd56d78",
   "metadata": {},
   "source": [
    "<img src=\"demo.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee8984e-4bfc-427f-ae7a-7b9af70853d5",
   "metadata": {},
   "source": [
    "## Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e604c1dc-c33d-4699-af11-005ee76ad0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import google_cloud_pipeline_components\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474e1abd-7a8e-46b1-bcb3-ad389b8ebda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.8.7', '0.1.9', '2.6.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.__version__, google_cloud_pipeline_components.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930cd6b-5db6-433a-8d91-08cf486b6f0e",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67aab282-ddf8-4b62-9190-ada06eaec5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.v2.dsl import component, Input, Output, OutputPath, Dataset, Model, InputPath\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983de122-9c42-4d0a-9c01-2654ce4e19bb",
   "metadata": {},
   "source": [
    "### 1. Load Data Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f55f06a1-9b4b-4950-a95d-76153947d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def load_data(\n",
    "    dataset: Output[Dataset]\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    with open(dataset.path, \"wb\") as f:\n",
    "        np.savez(\n",
    "            f,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            x_test=x_test,\n",
    "            y_test=y_test\n",
    "        )\n",
    "    print(f\"Saved On : {dataset.path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d6b30-de43-44b5-9692-cff372036de1",
   "metadata": {},
   "source": [
    "### 2. Preprocess Data Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a2bfe2b8-27ac-4722-a8e3-e8180b57d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def proc_data(\n",
    "    dataset_input: Input[Dataset],\n",
    "    dataset_output: Output[Dataset]\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    print(f\"Load on : {dataset_input.path}\")\n",
    "    with open(dataset_input.path, \"rb\") as f:\n",
    "        dataset = np.load(f)\n",
    "        x_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "        x_test, y_test = dataset[\"x_test\"], dataset[\"y_test\"]\n",
    "    \n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    \n",
    "    print(\"train x shape: \", x_train.shape)\n",
    "    print(\"test x shape: \", x_test.shape)\n",
    "    \n",
    "    with open(dataset_output.path, \"wb\") as f:\n",
    "        np.savez(\n",
    "            f,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            x_test=x_test,\n",
    "            y_test=y_test\n",
    "        )\n",
    "    print(f\"Saved On : {dataset_output.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc430364-81b3-42ec-8b81-0c8b1a9bf473",
   "metadata": {},
   "source": [
    "### 3. Train Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8c93e41f-2d3d-4fc7-a28d-3db7f662749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def train_linear(\n",
    "    dataset_input: Input[Dataset],\n",
    "    mnist_model: Output[Model]\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    print(f\"Load on : {dataset_input.path}\")\n",
    "    with open(dataset_input.path, \"rb\") as f:\n",
    "        dataset = np.load(f)\n",
    "        x_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "        x_test, y_test = dataset[\"x_test\"], dataset[\"y_test\"]\n",
    "    \n",
    "    print(\"train x shape: \", x_train.shape)\n",
    "    print(\"test x shape: \", x_test.shape)\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=2)\n",
    "    train_acc = history.history['accuracy'][-1]\n",
    "    mnist_model.metadata['train accuracy'] = train_acc\n",
    "        \n",
    "    model.save(mnist_model.path)\n",
    "    \n",
    "    print(f\"Model saved On : {mnist_model.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ebe63-d5d3-4aca-94fa-3a9b538c855c",
   "metadata": {},
   "source": [
    "### 3.1 Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8fffd1f5-89b0-4a68-ac1b-403c888724ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def train_cnn(\n",
    "    dataset_input: Input[Dataset],\n",
    "    mnist_model: Output[Model]\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    print(f\"Load on : {dataset_input.path}\")\n",
    "    with open(dataset_input.path, \"rb\") as f:\n",
    "        dataset = np.load(f)\n",
    "        x_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "        x_test, y_test = dataset[\"x_test\"], dataset[\"y_test\"]\n",
    "    \n",
    "    print(\"train x shape: \", x_train.shape)\n",
    "    print(\"test x shape: \", x_test.shape)\n",
    "    \n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=2)\n",
    "    train_acc = history.history['accuracy'][-1]\n",
    "    mnist_model.metadata['train accuracy'] = train_acc\n",
    "    \n",
    "    model.save(mnist_model.path)\n",
    "    \n",
    "    print(f\"Model saved On : {mnist_model.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6ab9e-137c-4f6c-b2a0-35d903db2885",
   "metadata": {},
   "source": [
    "### 4. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6e08cbf4-d397-48d9-b524-8dd43dae8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def evaluate_models(\n",
    "    dataset_input: Input[Dataset],\n",
    "    mnist_linear_model: Input[Model],\n",
    "    mnist_cnn_model: Input[Model]\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(dataset_input.path, \"rb\") as f:\n",
    "        dataset = np.load(f)\n",
    "        x_test, y_test = dataset[\"x_test\"], dataset[\"y_test\"]\n",
    "    \n",
    "    model_linear = tf.keras.models.load_model(mnist_linear_model.path)\n",
    "    model_cnn = tf.keras.models.load_model(mnist_cnn_model.path)\n",
    "\n",
    "    # Evalute Linear Model\n",
    "    loss, acc = model_linear.evaluate(x_test, y_test)\n",
    "    mnist_linear_model.metadata['loss'] = loss\n",
    "    mnist_linear_model.metadata['acc'] = acc\n",
    "    \n",
    "    # Evalute CNN Model\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    loss, acc = model_cnn.evaluate(x_test, y_test)\n",
    "    mnist_cnn_model.metadata['loss'] = loss\n",
    "    mnist_cnn_model.metadata['acc'] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b4216b-f767-48b6-a899-2bf892466b0d",
   "metadata": {},
   "source": [
    "### 100. Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "33384e7c-6c51-4115-be23-15f444dad298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='mnist-pipeline',\n",
    "    description='An example pipeline that performs load mnist data.',\n",
    "    pipeline_root='gs://suwan_test/'\n",
    ")\n",
    "def mnist_pipeline():\n",
    "    load_data_task = load_data()\n",
    "    \n",
    "    print(load_data_task.output)\n",
    "    \n",
    "    proc_data_task = proc_data(\n",
    "        dataset_input=load_data_task.output\n",
    "    )\n",
    "    train_linear_task = train_linear(\n",
    "        dataset_input=proc_data_task.output\n",
    "    )\n",
    "    train_cnn_task = train_cnn(\n",
    "        dataset_input=proc_data_task.output\n",
    "    )\n",
    "    evaluate_models_task = evaluate_models(\n",
    "        dataset_input=proc_data_task.output,\n",
    "        mnist_linear_model=train_linear_task.output,\n",
    "        mnist_cnn_model=train_cnn_task.output,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb1008-9960-41ea-8480-c3f6058cf226",
   "metadata": {},
   "source": [
    "### 101. Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a744cd6-95dc-4de6-9570-9cca0a9db1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{pipelineparam:op=load-data;name=dataset}}\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=mnist_pipeline,\n",
    "    package_path=\"mnist_pipeline.json\"\n",
    ")\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"mnist_pipeline\",\n",
    "    template_path=\"mnist_pipeline.json\",\n",
    "    job_id=f\"mnist-pipeline-{TIMESTAMP}\",\n",
    "    enable_caching=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0b3211d3-dd9e-4493-b322-78bc4adf339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mnist-pipeline-20211031081001?project=697793444829\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-20211031081001\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273de5d-0118-4258-b80a-1e5d4ff869a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
