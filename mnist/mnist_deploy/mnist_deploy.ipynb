{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6bd7a5-e63a-46b7-9d06-5c5a07674fd0",
   "metadata": {},
   "source": [
    "# MNIST Train Implements\n",
    "\n",
    "- 1. Load Data Component\n",
    "- 2. Train Linear Component\n",
    "- 3. Deploy Model Component\n",
    "- 4. Pipeline function\n",
    "- 5. Run on Vertex AI\n",
    "\n",
    "<img src=\"demo2.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60a6ee-d63e-474d-8e3f-609b212a280c",
   "metadata": {},
   "source": [
    "### 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f44de09-a516-4abe-b2c0-9d2943718466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, ClassificationMetrics, Metrics, component)\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from typing import NamedTuple\n",
    "\n",
    "# We'll use this beta library for metadata querying\n",
    "from google.cloud import aiplatform_v1beta1\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293603c-57da-41f8-853f-0230514aa05c",
   "metadata": {},
   "source": [
    "### 1. Load Data Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2558fe46-41f3-4a6b-9cde-3e23ea479670",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def load_data(\n",
    "    dataset: Output[Dataset]\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    \n",
    "    with open(dataset.path, \"wb\") as f:\n",
    "        np.savez(\n",
    "            f,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            x_test=x_test,\n",
    "            y_test=y_test\n",
    "        )\n",
    "    print(f\"Saved On : {dataset.path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101676de-2539-4f30-a707-15f7afd57bae",
   "metadata": {},
   "source": [
    "### 2. Train Linear Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebafd1e1-9b77-4c75-b88f-1145cb7e5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def train(\n",
    "    dataset: Input[Dataset],\n",
    "    model: Output[Model],\n",
    "    metrics: Output[Metrics],\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(dataset.path, \"rb\") as f:\n",
    "        dataset = np.load(f)\n",
    "        x_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "        x_test, y_test = dataset[\"x_test\"], dataset[\"y_test\"]\n",
    "        \n",
    "    linear_model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    linear_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = linear_model.fit(x_train, y_train, epochs=3)\n",
    "    \n",
    "    loss, acc = linear_model.evaluate(x_test, y_test)\n",
    "    print(f\"acc : {acc}\")\n",
    "\n",
    "    metrics.log_metric(\"accuracy\",(acc * 100.0))\n",
    "    metrics.log_metric(\"framework\", \"Tensorflow\")\n",
    "    metrics.log_metric(\"Model\", \"LinearModel\")\n",
    "    metrics.log_metric(\"dataset_size\", len(x_train))\n",
    "\n",
    "    linear_model.save(model.path)\n",
    "    print(f\"Model saved on : {model.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31d901-7d65-4d48-826b-f4960fef9354",
   "metadata": {},
   "source": [
    "### 3. Deploy Model Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e887042-d660-41c6-b86d-18e7f08e7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"tensorflow\", \"numpy\"]\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"mnist-model-pipeline\",\n",
    "        artifact_uri = model.uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c284d64-9fa3-415e-8980-df02530c0b7a",
   "metadata": {},
   "source": [
    "### 4. Pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07673afc-c53c-493a-a159-63a488e663b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"<BUCKET_URI>\"\n",
    "PROJECT_ID = \"<PROJECT_ID>\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac404fe5-48f5-4f3e-a595-71c1c1d1a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline.\n",
    "    name=\"mnist-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    data_task = load_data()\n",
    "\n",
    "    train_task = train(\n",
    "        dataset=data_task.output\n",
    "    )\n",
    "    deploy_task = deploy_model(\n",
    "        model=train_task.outputs[\"model\"],\n",
    "        project=project,\n",
    "        region=region\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2e8a67-6669-4263-aa73-4b1343dbb255",
   "metadata": {},
   "source": [
    "### 5. Run on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63c27cfd-809b-4b9c-9eb4-a7d5270d276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mnist-pipeline-small-20211031101853?project=697793444829\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/697793444829/locations/us-central1/pipelineJobs/mnist-pipeline-small-20211031101853\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"mnist_pipeline.json\"\n",
    ")\n",
    "\n",
    "run1 = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"mnist-pipeline\",\n",
    "    template_path=\"mnist_pipeline.json\",\n",
    "    job_id=\"mnist-pipeline-small-{0}\".format(TIMESTAMP),\n",
    "    parameter_values={},\n",
    "    enable_caching=True,\n",
    ")\n",
    "\n",
    "run1.run()\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
